{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Bonus2_FedAvg_SHedaya.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DpBH8FcYlsCd",
        "Fnr8jyqDlsCm",
        "iebj9DGflsDB",
        "Qumyi557lsDE",
        "s9VCvPtolsDR",
        "ERT3wqOllsDf"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyf8kWL7lsB9",
        "colab_type": "text"
      },
      "source": [
        "# Bonus 1: Numerical Optimization for Logistic Regression.\n",
        "\n",
        "### Name: Sarita Hedaya\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0FJFdPgSgI8z"
      },
      "source": [
        "1. Read the lecture note [click here (Links to an external site.)]  and the corresponding research papers.\n",
        "\n",
        " \n",
        "\n",
        "2. Implement federated averaging (easier) and/or decentralized optimization (harder). 2 bonus points for each. If you do both, submit them as two separate IPYNB files.\n",
        "\n",
        " \n",
        "\n",
        "3. Data: use the data and template of Bonus 1.\n",
        "\n",
        " \n",
        "\n",
        "4. Requirement for federated averaging:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Use 4 worker nodes.\n",
        "*   Use GD and SGD (with batch size b=1).\n",
        "* Set the number of local iterations to q=1 and 8.\n",
        "* Plot (training) objective function against epochs. Note that one epoch means every sample is visited exactly once.\n",
        "* Note also that there are 4 lines in your plot. (GD with q=1, GD with q=8, SGD with q=1, SGD with q=8.)\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "5. Requirement for decentralized optimization:\n",
        "\n",
        "* Use 7 worker nodes; the connection must be the same as the figure in the lecture note.\n",
        "* Use GD.\n",
        "* Try weighted averaging (give a worker's own parameter a higher weight than its neighbors' parameters) and simple averaging (everyone has the same weight).\n",
        "* Plot (training) objective function against epochs. \n",
        "* Note that there are at least 2 lines in your plot. (Corresponding to the weighting schemes.)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogbmRbFclsCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hTxdXWJlsCG",
        "colab_type": "text"
      },
      "source": [
        "# 1. Data processing\n",
        "\n",
        "- Download the Diabete dataset from https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/diabetes\n",
        "- Load the data using sklearn.\n",
        "- Preprocess the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubph9GGqlsCH",
        "colab_type": "text"
      },
      "source": [
        "## 1.1. Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsHI3SOqm4lg",
        "colab_type": "code",
        "outputId": "14e42dd7-89ee-4493-8196-857ff82b5148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs2NtVkFlsCJ",
        "colab_type": "code",
        "outputId": "49fdd0d7-33f3-4550-c586-dabfd9ac2f06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn import datasets\n",
        "import numpy\n",
        "\n",
        "x_sparse, y = datasets.load_svmlight_file('/content/drive/My Drive/F19/CS 583 - Deep Learning/diabetes.txt')\n",
        "x = x_sparse.todense()\n",
        "\n",
        "print('Shape of x: ' + str(x.shape))\n",
        "print('Shape of y: ' + str(y.shape))"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x: (768, 8)\n",
            "Shape of y: (768,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RzPmSAjlsCN",
        "colab_type": "text"
      },
      "source": [
        "## 1.2. Partition to training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuF9440ElsCP",
        "colab_type": "code",
        "outputId": "62340e50-327e-43f9-8526-778704304c44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# partition the data to training and test sets\n",
        "n = x.shape[0]\n",
        "n_train = int(numpy.ceil(n * 0.8))\n",
        "n_test = n - n_train\n",
        "\n",
        "rand_indices = numpy.random.permutation(n)\n",
        "train_indices = rand_indices[0:n_train]\n",
        "test_indices = rand_indices[n_train:n]\n",
        "\n",
        "x_train = x[train_indices, :]\n",
        "x_test = x[test_indices, :]\n",
        "y_train = y[train_indices].reshape(n_train, 1)\n",
        "y_test = y[test_indices].reshape(n_test, 1)\n",
        "\n",
        "print('Shape of x_train: ' + str(x_train.shape))\n",
        "print('Shape of x_test: ' + str(x_test.shape))\n",
        "print('Shape of y_train: ' + str(y_train.shape))\n",
        "print('Shape of y_test: ' + str(y_test.shape))"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train: (615, 8)\n",
            "Shape of x_test: (153, 8)\n",
            "Shape of y_train: (615, 1)\n",
            "Shape of y_test: (153, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqehSVqelsCT",
        "colab_type": "text"
      },
      "source": [
        "## 1.3. Feature scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KodPvsAolsCU",
        "colab_type": "text"
      },
      "source": [
        "Use the standardization to trainsform both training and test features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y_7yicGlsCW",
        "colab_type": "code",
        "outputId": "6452e457-9bc7-41fb-edeb-0f5a63553292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "# Standardization\n",
        "import numpy\n",
        "\n",
        "# calculate mu and sig using the training set\n",
        "d = x_train.shape[1]\n",
        "mu = numpy.mean(x_train, axis=0).reshape(1, d)\n",
        "sig = numpy.std(x_train, axis=0).reshape(1, d)\n",
        "\n",
        "# transform the training features\n",
        "x_train = (x_train - mu) / (sig + 1E-6)\n",
        "\n",
        "# transform the test features\n",
        "x_test = (x_test - mu) / (sig + 1E-6)\n",
        "\n",
        "print('test mean = ')\n",
        "print(numpy.mean(x_test, axis=0))\n",
        "\n",
        "print('test std = ')\n",
        "print(numpy.std(x_test, axis=0))"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test mean = \n",
            "[[-0.02772253 -0.01282227 -0.03617019 -0.12011721 -0.13112678  0.05843218\n",
            "  -0.00777865  0.0348263 ]]\n",
            "test std = \n",
            "[[1.06239624 1.03295418 1.20271906 1.0481506  0.80986955 1.13534821\n",
            "  1.1623515  1.09814328]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqHCdHZvlsCZ",
        "colab_type": "text"
      },
      "source": [
        "## 1.4. Add a dimension of all ones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucpobwr4lsCa",
        "colab_type": "code",
        "outputId": "61441acd-4b85-4c04-c7cb-0d1c7a8f07c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "n_train, d = x_train.shape\n",
        "x_train = numpy.concatenate((x_train, numpy.ones((n_train, 1))), axis=1)\n",
        "\n",
        "n_test, d = x_test.shape\n",
        "x_test = numpy.concatenate((x_test, numpy.ones((n_test, 1))), axis=1)\n",
        "\n",
        "print('Shape of x_train: ' + str(x_train.shape))\n",
        "print('Shape of x_test: ' + str(x_test.shape))"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train: (615, 9)\n",
            "Shape of x_test: (153, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ3MXygqg_mO",
        "colab_type": "text"
      },
      "source": [
        "# 2. Define class Worker and Server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ3tU0kblP8G",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Worker Class definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW6yflHVhPyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Worker:\n",
        "    def __init__(self, x, y, batch_size=None):\n",
        "        self.x = x # s−by−d local feature matrix\n",
        "        self.y = y # s-by-1 local labels matrix\n",
        "        self.s = x.shape[0] # number of local samples\n",
        "        self.d = x.shape[1] # number of features\n",
        "        self.w = numpy.zeros((d, 1)) # d-by-1 model parameter vector\n",
        "\n",
        "    def set_param(self, w):\n",
        "        self.w = w\n",
        "\n",
        "    def loss(self):\n",
        "        \"\"\" Computes the local loss \"\"\"\n",
        "        yx = numpy.multiply(self.y, self.x) # s−by−d matrix\n",
        "        yxw = numpy.dot(yx, self.w) # s-by-1 matrix\n",
        "        vec1 = numpy.exp(-yxw) #s-by-1 matrix\n",
        "        vec2 = numpy.log(1 + vec1) # s-by-1 matrix\n",
        "        return numpy.sum(vec2)\n",
        "\n",
        "    def gradient(self):\n",
        "        \"\"\" Computes the local gradient \"\"\"\n",
        "        yx = numpy.multiply(self.y, self.x) # s−by−d matrix\n",
        "        yxw = numpy.dot(yx, self.w) # s-by-1 matrix\n",
        "        vec1 = numpy.exp(yxw) #s-by-1 matrix\n",
        "        vec2 = numpy.divide(yx, 1 + vec1) # s-by-d \n",
        "        g = -numpy.sum(vec2, axis=0).reshape(self.d, 1) # d-by-1\n",
        "        return g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MILOD9HFlTgQ",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 Server Class definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMXRPq82jJya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Server:\n",
        "  def __init__(self, m, n, d):\n",
        "    self.m = m\n",
        "    self.n = n\n",
        "    self.d = d\n",
        "    self.w = numpy.zeros((d, 1))\n",
        "    self.g = numpy.zeros((d, 1))\n",
        "    self.v = numpy.zeros((d, 1))\n",
        "    self.loss = 0\n",
        "    self.obj = 0\n",
        "    \n",
        "  def broadcast(self):\n",
        "    return self.w\n",
        "  \n",
        "  def aggregate(self, grads, losses):\n",
        "    \"\"\" Sum the gradients and loss functions evaluated by the workers\n",
        "    Args: \n",
        "      grads: a list of d-by-1 vectors\n",
        "      losses: a list of scalars\n",
        "    \"\"\"\n",
        "    self.g = numpy.zeros((self.d, 1))\n",
        "    self.loss = 0\n",
        "    for k in range(self.m):\n",
        "      self.g += grads[k]\n",
        "      self.loss += losses[k]\n",
        "      \n",
        "  def gradient(self, lam):\n",
        "    \"\"\" Compute the gradient from loss and regularization \"\"\"\n",
        "    self.g = self.g / self.n + lam * self.w\n",
        "    \n",
        "  def objective(self, lam):\n",
        "    \"\"\" Compute objective function = sum of loss and regularization \"\"\"\n",
        "    reg = lam / 2 * numpy.sum(self.w * self.w)\n",
        "    self.obj = self.loss / self.n + reg\n",
        "    return self.obj\n",
        "  \n",
        "  \n",
        "  def agd(self, alpha, beta):\n",
        "    \"\"\" Update the model paramteters using accelerated gradient descent.\n",
        "    Args:\n",
        "      alpha: learning rate\n",
        "      beta: momentum parameter\n",
        "    \"\"\"\n",
        "    self.v *= beta\n",
        "    self.v += self.g\n",
        "    self.w -= alpha * self.v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vGSEvuTlZp0",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAY_T8eNlylJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "def create_server_workers(m, x, y):\n",
        "  n, d = x.shape\n",
        "  s = math.floor(n / m)\n",
        "  server = Server(m, n, d)\n",
        "  workers = []\n",
        "  \n",
        "  for i in range(m):\n",
        "    indeces = list(range(i*s, (i + 1)*s))\n",
        "    worker = Worker(x[indeces, :], y[indeces, :])\n",
        "    workers.append(worker)\n",
        "    \n",
        "  return server, workers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7G_2U0AErcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = 4\n",
        "server, workers = create_server_workers(4, x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZB-3rV_mvvw",
        "colab_type": "text"
      },
      "source": [
        "### Gradient Descent parallel computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6jI29FyE-Su",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "83358c92-3f79-4320-c745-1b7e4655e85b"
      },
      "source": [
        "lam = 1E-6\n",
        "alpha = 1E-1\n",
        "beta=0.9\n",
        "max_epoch=50\n",
        "\n",
        "\n",
        "objvals_gd = []\n",
        "\n",
        "for t in range(max_epoch):\n",
        "    # step1: broadcast\n",
        "    w = server.broadcast()\n",
        "    for i in range(m):\n",
        "        workers[i].set_param(w)\n",
        "\n",
        "    # step2: perform worker's local computations\n",
        "    grads=[]\n",
        "    losses=[]\n",
        "    for i in range(m):\n",
        "        g = workers[i].gradient()\n",
        "        grads.append(g)\n",
        "\n",
        "        l = workers[i].loss()\n",
        "        losses.append(l)\n",
        "\n",
        "    # step3: aggregate worker's output\n",
        "    server.aggregate(grads, losses)\n",
        "\n",
        "    # step4: server update the model params\n",
        "    server.gradient(lam)\n",
        "    obj = server.objective(lam)\n",
        "    print(\"objective function value at \", str(t+1), \" = \", str(obj))\n",
        "    objvals_gd.append(obj)\n",
        "    server.agd(alpha, beta)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "objective function value at  1  =  0.6897659748011163\n",
            "objective function value at  2  =  0.677537867443514\n",
            "objective function value at  3  =  0.6561695347979073\n",
            "objective function value at  4  =  0.6296167442517455\n",
            "objective function value at  5  =  0.601761942067588\n",
            "objective function value at  6  =  0.5756481277630227\n",
            "objective function value at  7  =  0.5531106713357387\n",
            "objective function value at  8  =  0.5348435258500475\n",
            "objective function value at  9  =  0.5207251092734227\n",
            "objective function value at  10  =  0.5101872560673841\n",
            "objective function value at  11  =  0.5025018371485238\n",
            "objective function value at  12  =  0.4969567083019826\n",
            "objective function value at  13  =  0.4929418739258109\n",
            "objective function value at  14  =  0.48997777045224555\n",
            "objective function value at  15  =  0.4877118998911982\n",
            "objective function value at  16  =  0.48590097558950346\n",
            "objective function value at  17  =  0.4843883651346669\n",
            "objective function value at  18  =  0.48308182379749254\n",
            "objective function value at  19  =  0.48193377256418374\n",
            "objective function value at  20  =  0.48092494699555144\n",
            "objective function value at  21  =  0.4800515529648018\n",
            "objective function value at  22  =  0.47931574818867523\n",
            "objective function value at  23  =  0.4787191206518115\n",
            "objective function value at  24  =  0.47825875754869085\n",
            "objective function value at  25  =  0.4779254529272344\n",
            "objective function value at  26  =  0.4777035801133127\n",
            "objective function value at  27  =  0.4775721571806487\n",
            "objective function value at  28  =  0.4775066604004358\n",
            "objective function value at  29  =  0.47748118825086194\n",
            "objective function value at  30  =  0.4774706413744116\n",
            "objective function value at  31  =  0.4774526560469705\n",
            "objective function value at  32  =  0.47740910555915395\n",
            "objective function value at  33  =  0.4773270613556431\n",
            "objective function value at  34  =  0.4771991795774795\n",
            "objective function value at  35  =  0.47702354409189246\n",
            "objective function value at  36  =  0.47680304959095554\n",
            "objective function value at  37  =  0.4765444444212529\n",
            "objective function value at  38  =  0.4762571708965753\n",
            "objective function value at  39  =  0.47595214154098703\n",
            "objective function value at  40  =  0.47564057554260647\n",
            "objective function value at  41  =  0.4753329945688587\n",
            "objective function value at  42  =  0.4750384455701326\n",
            "objective function value at  43  =  0.4747639848391976\n",
            "objective function value at  44  =  0.4745144263845989\n",
            "objective function value at  45  =  0.47429233163960516\n",
            "objective function value at  46  =  0.47409819852499696\n",
            "objective function value at  47  =  0.47393079660657006\n",
            "objective function value at  48  =  0.4737875912117884\n",
            "objective function value at  49  =  0.473665201808645\n",
            "objective function value at  50  =  0.4735598471579399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JqzvcAIDs8h",
        "colab_type": "text"
      },
      "source": [
        "### SGD with parallel computation\n",
        "\n",
        "Helper code first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvXaC1VblsC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate the objective Q_i and the gradient of Q_i\n",
        "# Inputs:\n",
        "#     w: d-by-1 matrix\n",
        "#     xi: 1-by-d matrix\n",
        "#     yi: scalar\n",
        "#     lam: scalar, the regularization parameter\n",
        "# Return:\n",
        "#     obj: scalar, the objective Q_i\n",
        "#     g: d-by-1 matrix, gradient of Q_i\n",
        "def stochastic_objective_gradient(w, xi, yi, lam):\n",
        "    d = xi.shape[0]\n",
        "    yx = yi * xi # 1-by-d matrix\n",
        "    yxw = float(numpy.dot(yx, w)) # scalar\n",
        "    \n",
        "    # calculate objective function Q_i\n",
        "    loss = numpy.log(1 + numpy.exp(-yxw)) # scalar\n",
        "    reg = lam / 2 * numpy.sum(w * w) # scalar\n",
        "    obj = loss + reg\n",
        "    \n",
        "    # calculate stochastic gradient\n",
        "    g_loss = -yx.T / (1 + numpy.exp(yxw)) # d-by-1 matrix\n",
        "    g = g_loss + lam * w # d-by-1 matrix\n",
        "    \n",
        "    return obj, g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G4Scc8s6-y0C",
        "colab": {}
      },
      "source": [
        "lam = 1E-6\n",
        "alpha = 1E-1\n",
        "beta=0.9\n",
        "max_epoch=50\n",
        "\n",
        "\n",
        "objvals_gd = []\n",
        "\n",
        "for t in range(max_epoch):\n",
        "    # step1: broadcast\n",
        "    w = server.broadcast()\n",
        "    for i in range(m):\n",
        "        workers[i].set_param(w)\n",
        "\n",
        "    # step2: perform worker's local computations\n",
        "    grads=[]\n",
        "    losses=[]\n",
        "    for i in range(m):\n",
        "        for sample_id in range(len(workers[i].x)):\n",
        "            obj, g = stochastic_objective_gradient(workers[i].w, workers[i].x[sample_id], workers[i].y[sample_id], lam)\n",
        "\n",
        "\n",
        "    # step3: aggregate worker's output\n",
        "    server.aggregate(grads, losses)\n",
        "\n",
        "    # step4: server update the model params\n",
        "    server.gradient(lam)\n",
        "    obj = server.objective(lam)\n",
        "    print(\"objective function value at \", str(t+1), \" = \", str(obj))\n",
        "    objvals_gd.append(obj)\n",
        "    server.agd(alpha, beta)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbO4-gROm04d",
        "colab_type": "text"
      },
      "source": [
        "### Gradient descent Federated Average"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suba3tyJJYng",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "5cb3fc1a-c7a2-4bd2-9143-385d1fff5a26"
      },
      "source": [
        "lam = 1E-6\n",
        "alpha = 1E-1\n",
        "beta=0.9\n",
        "max_epoch=50\n",
        "local_iters = 8\n",
        "\n",
        "objvals_gd_q8 = []\n",
        "\n",
        "\n",
        "\n",
        "for t in range(int(max_epoch/local_iters)):\n",
        "    # step1: broadcast\n",
        "    w = server.broadcast()\n",
        "    for i in range(m):\n",
        "        workers[i].set_param(w)\n",
        "\n",
        "    # step2: perform worker's local computations\n",
        "    grads = []\n",
        "    losses = []\n",
        "    # print(grads)\n",
        "    # print(losses)        \n",
        "\n",
        "    # g_per_iter.average(axis=1)\n",
        "\n",
        "    for i in range(m):\n",
        "        worker_grads = numpy.zeros((local_iters, 9, 1))\n",
        "        worker_losses = numpy.zeros((local_iters))\n",
        "\n",
        "        for q in range(local_iters):\n",
        "            g_per_iter = workers[i].gradient()\n",
        "            worker_grads[q] = g_per_iter\n",
        "\n",
        "            loss_per_iter = workers[i].loss()\n",
        "            worker_losses[q] = loss_per_iter\n",
        "            \n",
        "        avg_worker_grads = numpy.average(worker_grads, axis=0)\n",
        "        grads.append(avg_worker_grads)\n",
        "\n",
        "        avg_worker_losses = numpy.average(worker_losses, axis=0)\n",
        "\n",
        "        losses.append(avg_worker_losses)\n",
        "\n",
        "    # step3: aggregate worker's output\n",
        "    server.aggregate(grads, losses)\n",
        "\n",
        "    # step4: server update the model params\n",
        "    server.gradient(lam)\n",
        "    obj = server.objective(lam)\n",
        "    print(\"objective function value at\", str(t*local_iters +1), \" = \", str(obj))\n",
        "    objvals_gd_q8.append(obj)\n",
        "    server.agd(alpha, beta)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "objective function value at 1  =  0.6897659748011163\n",
            "objective function value at 9  =  0.677537867443514\n",
            "objective function value at 17  =  0.6561695347979073\n",
            "objective function value at 25  =  0.6296167442517455\n",
            "objective function value at 33  =  0.601761942067588\n",
            "objective function value at 41  =  0.5756481277630227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAgRO1APLiCY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "3e93c33b-9447-4280-e8a2-0a5aef100301"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "\n",
        "epochs_gd = range(len(objvals_gd))\n",
        "epochs_gd_q8 = range(0, len(objvals_gd_q8)*local_iters, local_iters)\n",
        "\n",
        "\n",
        "line0, = plt.plot(epochs_gd, objvals_gd, '--b', LineWidth=4)\n",
        "line1, = plt.plot(epochs_gd_q8, objvals_gd_q8, '-b', LineWidth=2)\n",
        "\n",
        "# line2, = plt.plot(epochs_sgd, objvals_sgd, '--r', LineWidth=4)\n",
        "# line3, = plt.plot(epochs_sgd_q8, objvals_sgd_q8, '-r', LineWidth=2)\n",
        "\n",
        "plt.xlabel('Epochs', FontSize=20)\n",
        "plt.ylabel('Objective Value', FontSize=20)\n",
        "plt.xticks(FontSize=16)\n",
        "plt.yticks(FontSize=16)\n",
        "plt.legend([line0, line1], ['GD', 'GD_q=8', 'SGD', 'SGD_q=8'], fontsize=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "fig.savefig('compare_gd_with_q8.pdf', format='pdf', dpi=1200)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfwCxK39TSvXsxQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECRl0niBg-3f",
        "colab_type": "text"
      },
      "source": [
        "# **Bonus 2 ends here**"
      ]
    }
  ]
}